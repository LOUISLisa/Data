{
    "SeedUrl": "https://crypto.jobs/",
    "OutLinks": [
        "https://crypto.jobs/",
        "https://crypto.jobs/c/analyst",
        "https://crypto.jobs/c/business-development",
        "https://crypto.jobs/c/customer-support",
        "https://crypto.jobs/c/design",
        "https://crypto.jobs/c/marketing",
        "https://crypto.jobs/c/operations",
        "https://crypto.jobs/c/other",
        "https://crypto.jobs/c/sales",
        "https://crypto.jobs/c/tech",
        "https://crypto.jobs/cdn-cgi/l/email-protection",
        "https://crypto.jobs/jobs/apply/data-engineer-5-roles-san-francisco-california-on-demand-transportation-company-at-blockgram",
        "https://crypto.jobs/jobs/create",
        "https://crypto.jobs/jobs/data-engineer-5-roles-san-francisco-california-on-demand-transportation-company-at-blockgram",
        "https://crypto.jobs/jobs/frontend-engineer-at-bybit",
        "https://crypto.jobs/jobs/protocol-engineer-at-status-2",
        "https://crypto.jobs/jobs/senior-security-engineer-at-smartcontract",
        "https://crypto.jobs/locations/austin",
        "https://crypto.jobs/locations/bangalore",
        "https://crypto.jobs/locations/barcelona",
        "https://crypto.jobs/locations/berlin",
        "https://crypto.jobs/locations/boston",
        "https://crypto.jobs/locations/buenos-aires",
        "https://crypto.jobs/locations/cyberjaya",
        "https://crypto.jobs/locations/hong-kong",
        "https://crypto.jobs/locations/hyderabad",
        "https://crypto.jobs/locations/krakow",
        "https://crypto.jobs/locations/london",
        "https://crypto.jobs/locations/los-angeles",
        "https://crypto.jobs/locations/melbourne",
        "https://crypto.jobs/locations/mountain-view",
        "https://crypto.jobs/locations/new-york",
        "https://crypto.jobs/locations/oslo",
        "https://crypto.jobs/locations/palo-alto",
        "https://crypto.jobs/locations/pune",
        "https://crypto.jobs/locations/san-francisco",
        "https://crypto.jobs/locations/singapore",
        "https://crypto.jobs/locations/stockholm",
        "https://crypto.jobs/locations/tallinn",
        "https://crypto.jobs/locations/toronto",
        "https://crypto.jobs/locations/vienna",
        "https://crypto.jobs/partners",
        "https://crypto.jobs/remote",
        "https://crypto.jobs/rss",
        "https://crypto.jobs/skills/bitcoin",
        "https://crypto.jobs/skills/bitcoin-mining",
        "https://crypto.jobs/skills/bitcoin-wallet",
        "https://crypto.jobs/skills/cryptography",
        "https://crypto.jobs/skills/dapp",
        "https://crypto.jobs/skills/ethereum",
        "https://crypto.jobs/skills/security",
        "https://crypto.jobs/skills/serpent",
        "https://crypto.jobs/skills/smart-contract",
        "https://crypto.jobs/skills/solidity",
        "https://crypto.jobs/skills/trading",
        "https://crypto.jobs/skills/web3"
    ],
    "ContentType": "text/html; charset=UTF-8",
    "Parent": "https://crypto.jobs/locations/san-francisco",
    "DocumentType": "JobBoards",
    "Title": "Data Engineer \u2013 On-demand Transportation Company Job at Blockgram",
    "Hash": "E46D3195487D0361FBDD809CE58556CD",
    "Url": "https://crypto.jobs/jobs/data-engineer-5-roles-san-francisco-california-on-demand-transportation-company-at-blockgram",
    "CrawledDate": "2020-07-12",
    "DomainId": "crypto",
    "Language": "English",
    "TackIt": "false",
    "Body": " Blockgram\u2019s client is hiring 5+ Data Engineers to join their growing local team in San Francisco, California. These are all 12-month minimum contract roles with the potential for long-term growth at one of the fastest growing on-demand transportation companies in the world. We are looking for a tenacious, passionate software developer with a specific focus on data engineering to join their data engineering and business analytics team. These Data Engineers should have exceptional SQL experience and be proficient with Python. The project is to support the massive growth in both data and in business. The focus is on platforming existing extract, transform, and load (ETL) and ELT processes from PL/SQL to the client\u2019s standard framework of Python and ANSI compliant SQL. The current environment consists of the following: Looker, Tableau, Hadoop, Airflow, Python, SQL, Qubole etc. We are actively looking for the candidates with hands-on working experience with Python, SQL, and Oracle. Also, it is important to have experience with Data Warehousing for setting up reporting and analytical platforms with optimum performance and be well versed about Unix, Hadoop, and Hive, and of course BI/Reporting tools. In this role, you\u2019ll be responsible for bringing data into the platform, transforming it into a well-defined, consistent model, moving it to the best data stores to support API and analytics use cases, and making it easy for applications and consumers to access the data. If you\u2019re eager in working with the latest emerging data-driven technology and having the opportunity of utilizing powerful business intelligence (BI) and data visualization tools, this role is definitely for you! Requirements: - BS in Computer Science, Information Systems or related discipline - 2+ years of experience in data engineering and building large-scale data platforms, experience with Oracle - 2+ years of experience in SQL to discover, aggregate and extract data - 2+ years experience with Hadoop, Pig, Hive, Spark, Storm, and other BIG data technologies - 2+ years of experience with data visualization and BI tools, such as Tableau, Kibana, and Looker - Experience with databases such as MS SQL Server and MySQL - Experience in coding in Python. Node.js, or other object-oriented languages is a plus - Solid Linux and Windows administration skills, and understanding of system performance - Strong interpersonal and communication skills, flexibility, commitment to the team, and a positive attitude - Experience with data in the SaaS/subscription space is a plus - Experience with Apache Beam is a plus - Knowledge of Cassandra or other distributed data stores (Redis, MongoDB, MemCache, etc.) is a plus - Experience building CI/CD and server/deployment automation solutions is a plus This is a 12-month (minimum) contractor role and the chosen candidates will need to work from the headquarters in San downtown Francisco, California. Please note that we have a very generous referral program in place (blockgram.com/referrals) if you know any qualified candidates that would be good fits! https://hire.withgoogle.com/public/jobs/blockgramcom/view/P_AAAAAAFAABrLkTaaLLvDCh?trackingTag=httpsCryptoJobs Skills Apache Spark, BI/MI, Data Quality, Data Visualization, Hadoop, Hive, Pig, Python Compensation 100,000+ "
}