#!/bin/bash

DATA=/home/barb/Working/Data/
WEBSITES=${DATA}/WebSites
JAR=/home/barb/Working/Git/PostProcess/target/bbt-post-process-1.0.0-SNAPSHOT.jar
STATS=${DATA}/Statistics/

for d in $WEBSITES/*; do
    for f in $d/*_; do  
        echo "Working on: " $f 

        # The crawled output is the initial "index" data.  This data will
        # get added to as the steps below are executed.
        cp $f $f"index"

        # This is going to generate the BasicExtraFields...
        java -jar $JAR CrawledData $f

        # Add the extra fields that got generated by the process above to the
        # basic index fields that we stared with.
        java -jar $JAR UpdateIndex $f"index" $f"basic_extra_fields"

    done

    echo "Computing stats on: " %d

    # Now Compute Statistics for the WebSite
    # This is going to put 2 stats files in the directory with the website crawled data
    java -jar $JAR ComputeStats $d

    # Moving into the Statistics directory is not working yet.
    # Copy the Stats into the overall Statistics directory
    #for s in ${d}/stats*; do
    #   just_file=$(basename $s)
    #   echo "filename ... $just_file ;  domain ... $d  ; destination  $STATS/"website-"${just_file} "
    #   cp $d/${just_file} ${STATS}/"website-"${just_file}
    #done

    # Record whether or not there was a "Careers" URL

    # Linguistic analysis of URLs.
    # What is interesting for us to manually read / learn from ?


done 
